{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98960520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload to automatically reload modules when they are updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Union\n",
    "import joblib\n",
    "import psutil, shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from sarpyx.processor.core.focus import CoarseRDA\n",
    "from sarpyx.utils.zarr_utils import ZarrManager, dask_slice_saver, concatenate_slices_efficient\n",
    "\n",
    "# Only add path if not already added\n",
    "cwd = Path.cwd()\n",
    "sarpyx_path = cwd.parent\n",
    "if str(sarpyx_path) not in __import__('sys').path:\n",
    "    __import__('sys').path.append(str(sarpyx_path))\n",
    "    \n",
    "# Output directory for focused data\n",
    "output_dir = cwd.parent / 'focused_data' \n",
    "tmp_dir = output_dir / 'tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1cc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Input -------\n",
    "file_path = \"/Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1a-s1-raw-s-hh-20150519t121652-20150519t121725-005990-007b7d_burst_0.zarr\"\n",
    "# ------- Configure the handler for processing -------\n",
    "productName = Path(file_path).stem\n",
    "N_SLICES = 5\n",
    "# ------- Init -------\n",
    "# STEP1: Data Focusing Preparation\n",
    "handler = ZarrManager(file_path)\n",
    "# Starting focusing in steps:\n",
    "for SLICE_N in range(N_SLICES): \n",
    "    raw_data = handler.get_slice_block(slice_idx=SLICE_N, N_blocks=N_SLICES)\n",
    "    print(f'üìä Sliced raw data shape: {raw_data[\"echo\"].shape} ')\n",
    "\n",
    "    processor = CoarseRDA(\n",
    "                raw_data=raw_data,  # type: ignore\n",
    "                verbose=False,\n",
    "            )\n",
    "    print(f'üõ†Ô∏è Processor initialized with raw data of shape: {raw_data[\"echo\"].shape}')\n",
    "    processor.data_focus()\n",
    "    \n",
    "    raw = processor.raw_data\n",
    "    rc = processor.range_compressed_data\n",
    "    rcmc = processor.rcmc_data\n",
    "    az = processor.azimuth_compressed_data\n",
    "    metadata = raw_data['metadata'].to_dict()\n",
    "    ephemeris = raw_data['ephemeris'].to_dict()\n",
    "    \n",
    "    # Ensure all data types are as expected\n",
    "    assert isinstance(metadata, dict), f'Expected metadata to be dict, got {type(metadata)}'\n",
    "    assert isinstance(ephemeris, dict), f'Expected ephemeris to be dict, got {type(ephemeris)}'\n",
    "    assert isinstance(raw, np.ndarray), f'Expected raw data to be ndarray, got {type(raw)}'\n",
    "    assert isinstance(rc, np.ndarray), f'Expected range compressed data to be ndarray, got {type(rc)}'\n",
    "    assert isinstance(rcmc, np.ndarray), f'Expected rcmc data to be ndarray, got {type(rcmc)}'\n",
    "    assert isinstance(az, np.ndarray), f'Expected azimuth compressed data to be ndarray, got {type(az)}'\n",
    "\n",
    "    result = {'raw': raw, 'rc': rc, 'rcmc': rcmc, 'az': az, 'metadata': metadata, 'ephemeris': ephemeris}\n",
    "    zarr_path = tmp_dir / f\"processor_slice_{SLICE_N}.zarr\"\n",
    "    dask_slice_saver(result, zarr_path, chunks='auto', clevel=7)\n",
    "    \n",
    "    del processor, raw_data, raw, rc, rcmc, az, metadata, ephemeris, result  # Clear memory\n",
    "    \n",
    "    print(f'üíæ Slice {SLICE_N+1} saved to: {tmp_dir / f\"processor_slice_{SLICE_N+1}.pkl\"}')\n",
    " \n",
    "# --------- Concatenate slices efficiently ---------\n",
    "# STEP2: Cleanup: delete temporary dir\n",
    "tmp_files = [tmp_dir / f'processor_slice_{i}.zarr' for i in range(N_SLICES)]\n",
    "print(f'üîó Concatenating {len(tmp_files)} slices...')\n",
    "concatenated_data = concatenate_slices_efficient(tmp_files, output_dir / f'{productName}.zarr') # type: ignore\n",
    "print(f'‚úÖ Concatenated data saved to: {output_dir / f\"{productName}.zarr\"}')\n",
    "# --------- CLEANUP ---------\n",
    "if tmp_dir.exists():\n",
    "    for item in tmp_dir.iterdir():\n",
    "        if item.is_file():\n",
    "            item.unlink()\n",
    "        elif item.is_dir():\n",
    "            shutil.rmtree(item)\n",
    "    tmp_dir.rmdir()\n",
    "    print(f'üóëÔ∏è Temporary directory {tmp_dir} cleaned up.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
