{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ae955e",
   "metadata": {},
   "source": [
    "# API Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ad74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import gc\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "# ------ Custom Imports ------\n",
    "from sarpyx.processor.core.decode import S1L0Decoder\n",
    "from sarpyx.utils.io import find_dat_file\n",
    "# ------ Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "# ------ Setup paths ------\n",
    "cwd = Path.cwd().parent\n",
    "data_dir = cwd / 'extracted_data'\n",
    "output_dir = cwd / 'decoded_data'\n",
    "# ------ Functions ------\n",
    "def decode_s1_l0(input_file, output_dir):\n",
    "    decoder = S1L0Decoder()\n",
    "    decoder.decode_file(input_file, output_dir, save_to_zarr=True, headers_only=False)\n",
    "    del decoder\n",
    "    # Garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def retrieve_input_files(safe_folders, verbose=False):\n",
    "    \"\"\"Retrieve input files from SAFE folders.\"\"\"\n",
    "    pols = ['vh', 'vv', 'hh', 'hv']\n",
    "    input_files = []\n",
    "    folders_map = {x: [] for x in safe_folders}\n",
    "    for folder in safe_folders:\n",
    "        for pol in pols:\n",
    "            try:\n",
    "                input_file = find_dat_file(folder, pol)\n",
    "                input_files.append(input_file)\n",
    "                folders_map[folder].append(input_file)\n",
    "                if verbose:\n",
    "                    print(f'üìÅ Found {input_file.name} in {folder.name}')\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f'üìÅ No .dat file found in {folder.name}, checking next folder...')\n",
    "            pass\n",
    "    return input_files, folders_map\n",
    "            \n",
    "\n",
    "# Find first SAFE folder and .dat file\n",
    "safe_folders = [f for f in data_dir.rglob('*.SAFE') if f.is_dir()]\n",
    "input_files, folders_map = retrieve_input_files(safe_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2512fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/info_folders_map.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dump input_files and folders_map to joblib files\n",
    "joblib.dump(input_files, output_dir / 'info_input_files.joblib')\n",
    "joblib.dump(folders_map, output_dir / 'info_folders_map.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a single file\n",
    "single_file = input_files[0]  # Replace 0 with the desired index\n",
    "if single_file.is_file():\n",
    "    print(f'üîç Processing {single_file.name}...')\n",
    "    decode_s1_l0(single_file, output_dir)\n",
    "else:\n",
    "    print(f'‚ùå {single_file.name} is not a valid file.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
