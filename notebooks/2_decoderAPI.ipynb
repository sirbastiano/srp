{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ae955e",
   "metadata": {},
   "source": [
    "# API Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ad74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import gc\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "# ------ Custom Imports ------\n",
    "from sarpyx.processor.core.decode import S1L0Decoder\n",
    "from sarpyx.utils.io import find_dat_file\n",
    "# ------ Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "# ------ Setup paths ------\n",
    "cwd = Path.cwd().parent\n",
    "data_dir = cwd / 'extracted_data'\n",
    "output_dir = cwd / 'decoded_data'\n",
    "# ------ Functions ------\n",
    "def decode_s1_l0(input_file, output_dir):\n",
    "    decoder = S1L0Decoder()\n",
    "    decoder.decode_file(input_file, output_dir, save_to_zarr=True, headers_only=False)\n",
    "    del decoder\n",
    "    # Garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "def retrieve_input_files(safe_folders, verbose=False):\n",
    "    \"\"\"Retrieve input files from SAFE folders.\"\"\"\n",
    "    pols = ['vh', 'vv', 'hh', 'hv']\n",
    "    input_files = []\n",
    "    folders_map = {x: [] for x in safe_folders}\n",
    "    for folder in safe_folders:\n",
    "        for pol in pols:\n",
    "            try:\n",
    "                input_file = find_dat_file(folder, pol)\n",
    "                input_files.append(input_file)\n",
    "                folders_map[folder].append(input_file)\n",
    "                if verbose:\n",
    "                    print(f'üìÅ Found {input_file.name} in {folder.name}')\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f'üìÅ No .dat file found in {folder.name}, checking next folder...')\n",
    "            pass\n",
    "    return input_files, folders_map\n",
    "            \n",
    "# Find first SAFE folder and .dat file\n",
    "safe_folders = [f for f in data_dir.rglob('*.SAFE') if f.is_dir()]\n",
    "input_files, folders_map = retrieve_input_files(safe_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 10:31:03,053 - INFO - Processing file: /Data_large/marine/PythonProjects/SAR/sarpyx/extracted_data/BANGLADESH/S1B_S3_RAW__0SSV_20190202T115525_20190202T115541_014767_01B8AA_2BFE.SAFE/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa.dat\n",
      "2025-07-11 10:31:03,054 - INFO - File size: 417.0 MB\n",
      "2025-07-11 10:31:03,054 - INFO - Starting full decode process...\n",
      "2025-07-11 10:31:03,055 - INFO - Starting decode process for: /Data_large/marine/PythonProjects/SAR/sarpyx/extracted_data/BANGLADESH/S1B_S3_RAW__0SSV_20190202T115525_20190202T115541_014767_01B8AA_2BFE.SAFE/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa.dat\n",
      "2025-07-11 10:31:03,054 - INFO - File size: 417.0 MB\n",
      "2025-07-11 10:31:03,054 - INFO - Starting full decode process...\n",
      "2025-07-11 10:31:03,055 - INFO - Starting decode process for: /Data_large/marine/PythonProjects/SAR/sarpyx/extracted_data/BANGLADESH/S1B_S3_RAW__0SSV_20190202T115525_20190202T115541_014767_01B8AA_2BFE.SAFE/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa.dat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa.dat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decoded: 29812 packets [01:23, 356.86 packets/s]\n",
      "2025-07-11 10:32:26,601 - INFO - Decoded 29812 records from file\n",
      "2025-07-11 10:32:26,601 - WARNING - Starting an incomplete sub-commutated data cycle. (first index: 32.\n",
      "2025-07-11 10:32:26,602 - WARNING - Incomplete sub-commutated data cycle: 0\n",
      "2025-07-11 10:32:26,604 - WARNING - Incomplete sub-commutated data cycle: 20\n",
      "2025-07-11 10:32:26,606 - WARNING - Incomplete sub-commutated data cycle: 51\n",
      "decoded: 29812 packets [01:23, 356.86 packets/s]\n",
      "2025-07-11 10:32:26,601 - INFO - Decoded 29812 records from file\n",
      "2025-07-11 10:32:26,601 - WARNING - Starting an incomplete sub-commutated data cycle. (first index: 32.\n",
      "2025-07-11 10:32:26,602 - WARNING - Incomplete sub-commutated data cycle: 0\n",
      "2025-07-11 10:32:26,604 - WARNING - Incomplete sub-commutated data cycle: 20\n",
      "2025-07-11 10:32:26,606 - WARNING - Incomplete sub-commutated data cycle: 51\n",
      "2025-07-11 10:32:26,609 - WARNING - Incomplete sub-commutated data cycle: 82\n",
      "2025-07-11 10:32:26,612 - WARNING - Incomplete sub-commutated data cycle: 113\n",
      "2025-07-11 10:32:26,614 - WARNING - Incomplete sub-commutated data cycle: 144\n",
      "2025-07-11 10:32:26,617 - WARNING - Incomplete sub-commutated data cycle: 175\n",
      "2025-07-11 10:32:26,620 - WARNING - Incomplete sub-commutated data cycle: 206\n",
      "2025-07-11 10:32:26,609 - WARNING - Incomplete sub-commutated data cycle: 82\n",
      "2025-07-11 10:32:26,612 - WARNING - Incomplete sub-commutated data cycle: 113\n",
      "2025-07-11 10:32:26,614 - WARNING - Incomplete sub-commutated data cycle: 144\n",
      "2025-07-11 10:32:26,617 - WARNING - Incomplete sub-commutated data cycle: 175\n",
      "2025-07-11 10:32:26,620 - WARNING - Incomplete sub-commutated data cycle: 206\n",
      "2025-07-11 10:32:26,622 - WARNING - Incomplete sub-commutated data cycle: 237\n",
      "2025-07-11 10:32:26,625 - WARNING - Incomplete sub-commutated data cycle: 267\n",
      "2025-07-11 10:32:26,627 - WARNING - Incomplete sub-commutated data cycle: 298\n",
      "2025-07-11 10:32:26,630 - WARNING - Incomplete sub-commutated data cycle: 329\n",
      "2025-07-11 10:32:26,622 - WARNING - Incomplete sub-commutated data cycle: 237\n",
      "2025-07-11 10:32:26,625 - WARNING - Incomplete sub-commutated data cycle: 267\n",
      "2025-07-11 10:32:26,627 - WARNING - Incomplete sub-commutated data cycle: 298\n",
      "2025-07-11 10:32:26,630 - WARNING - Incomplete sub-commutated data cycle: 329\n",
      "2025-07-11 10:32:26,633 - WARNING - Incomplete sub-commutated data cycle: 360\n",
      "2025-07-11 10:32:26,635 - WARNING - Incomplete sub-commutated data cycle: 391\n",
      "2025-07-11 10:32:26,638 - WARNING - Incomplete sub-commutated data cycle: 422\n",
      "2025-07-11 10:32:26,641 - WARNING - Incomplete sub-commutated data cycle: 453\n",
      "2025-07-11 10:32:26,643 - WARNING - Incomplete sub-commutated data cycle: 479\n",
      "2025-07-11 10:32:26,633 - WARNING - Incomplete sub-commutated data cycle: 360\n",
      "2025-07-11 10:32:26,635 - WARNING - Incomplete sub-commutated data cycle: 391\n",
      "2025-07-11 10:32:26,638 - WARNING - Incomplete sub-commutated data cycle: 422\n",
      "2025-07-11 10:32:26,641 - WARNING - Incomplete sub-commutated data cycle: 453\n",
      "2025-07-11 10:32:26,643 - WARNING - Incomplete sub-commutated data cycle: 479\n",
      "2025-07-11 10:32:26,643 - INFO - 480 sub-commutated data cycles collected.\n",
      "2025-07-11 10:32:26,643 - INFO - 480 sub-commutated data cycles collected.\n",
      "2025-07-11 10:32:26,659 - INFO - 17 incomplete sub-commutated data cycles.\n",
      "2025-07-11 10:32:26,659 - INFO - 17 incomplete sub-commutated data cycles.\n",
      "2025-07-11 10:32:26,714 - INFO - Extracted ephemeris data with 463 records\n",
      "2025-07-11 10:32:26,714 - INFO - Extracted ephemeris data with 463 records\n",
      "2025-07-11 10:32:26,755 - INFO - Extracted 2 echo bursts\n",
      "2025-07-11 10:32:26,755 - INFO - Extracted 2 echo bursts\n",
      "2025-07-11 10:32:28,297 - INFO - Processed burst 0: (8229, 22012) radar samples, 8229 metadata records\n",
      "2025-07-11 10:32:28,297 - INFO - Processed burst 0: (8229, 22012) radar samples, 8229 metadata records\n",
      "2025-07-11 10:32:32,214 - INFO - Processed burst 1: (21175, 22020) radar samples, 21175 metadata records\n",
      "2025-07-11 10:32:32,214 - INFO - Processed burst 1: (21175, 22020) radar samples, 21175 metadata records\n",
      "2025-07-11 10:32:32,626 - INFO - Padded burst 0 from 22012 to 22020 samples\n",
      "2025-07-11 10:32:32,626 - INFO - Padded burst 0 from 22012 to 22020 samples\n",
      "2025-07-11 10:32:36,307 - INFO - Concatenated radar data shape: (29404, 22020)\n",
      "2025-07-11 10:32:36,307 - INFO - Concatenated radar data shape: (29404, 22020)\n",
      "2025-07-11 10:32:36,338 - INFO - Created unified dataset: (29404, 22020) total samples, 29404 metadata records from 2 bursts\n",
      "2025-07-11 10:32:36,338 - INFO - Created unified dataset: (29404, 22020) total samples, 29404 metadata records from 2 bursts\n",
      "2025-07-11 10:32:36,422 - INFO - Successfully decoded and unified data from 2 original bursts\n",
      "2025-07-11 10:32:36,423 - INFO - Saving data in Zarr format...\n",
      "2025-07-11 10:32:36,424 - INFO - Start -> data to Zarr format: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data\n",
      "2025-07-11 10:32:36,422 - INFO - Successfully decoded and unified data from 2 original bursts\n",
      "2025-07-11 10:32:36,423 - INFO - Saving data in Zarr format...\n",
      "2025-07-11 10:32:36,424 - INFO - Start -> data to Zarr format: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added metadata with 29404 records as zarr attributes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 10:35:46,134 - INFO - Saved unified echo data to Zarr: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa.zarr\n",
      "2025-07-11 10:35:46,135 - INFO -   - Echo shape: (29404, 22020)\n",
      "2025-07-11 10:35:46,136 - INFO -   - Metadata records: 29404\n",
      "2025-07-11 10:35:46,136 - INFO -   - Ephemeris records: 463\n",
      "2025-07-11 10:35:46,137 - INFO - Saved burst info: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa_burst_info.json\n",
      "2025-07-11 10:35:46,137 - INFO - Saved summary info as JSON: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa_info.json\n",
      "2025-07-11 10:35:46,138 - INFO - Created 1 Zarr file(s) and 4 other files\n",
      "2025-07-11 10:35:46,139 - INFO - \n",
      "================================================== ‚úÖ Processed. ==================================================\n",
      "2025-07-11 10:35:46,135 - INFO -   - Echo shape: (29404, 22020)\n",
      "2025-07-11 10:35:46,136 - INFO -   - Metadata records: 29404\n",
      "2025-07-11 10:35:46,136 - INFO -   - Ephemeris records: 463\n",
      "2025-07-11 10:35:46,137 - INFO - Saved burst info: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa_burst_info.json\n",
      "2025-07-11 10:35:46,137 - INFO - Saved summary info as JSON: /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa_info.json\n",
      "2025-07-11 10:35:46,138 - INFO - Created 1 Zarr file(s) and 4 other files\n",
      "2025-07-11 10:35:46,139 - INFO - \n",
      "================================================== ‚úÖ Processed. ==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added ephemeris with 463 records as zarr attributes\n",
      "Saved array to /Data_large/marine/PythonProjects/SAR/sarpyx/decoded_data/s1b-s3-raw-s-vv-20190202t115525-20190202t115541-014767-01b8aa.zarr with maximum compression (zstd-9, chunks=(512, 512))\n"
     ]
    }
   ],
   "source": [
    "# Optional: Dump info about input files and folders\n",
    "# dump input_files and folders_map to joblib files\n",
    "joblib.dump(input_files, output_dir / 'info_input_files.joblib')\n",
    "joblib.dump(folders_map, output_dir / 'info_folders_map.joblib')\n",
    "\n",
    "# ========== Main Processing ==========\n",
    "# Process a single file:\n",
    "single_file = input_files[0]  # Replace 0 with the desired index\n",
    "if single_file.is_file():\n",
    "    print(f'üîç Processing {single_file.name}...')\n",
    "    decode_s1_l0(single_file, output_dir)\n",
    "else:\n",
    "    print(f'‚ùå {single_file.name} is not a valid file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c747d24",
   "metadata": {},
   "source": [
    "## üîß Updated Unified Decoder with Padding Support\n",
    "\n",
    "The decoder has been updated to handle the case where different bursts have different numbers of samples per line. This is common in SAR data where burst boundaries may not align perfectly.\n",
    "\n",
    "### Solution: Adaptive Padding\n",
    "- **Problem**: Burst 0 had 22012 samples, Burst 1 had 22020 samples\n",
    "- **Solution**: Pad smaller bursts with zeros to match the largest burst width\n",
    "- **Benefits**: \n",
    "  - Preserves all original data\n",
    "  - Maintains data integrity\n",
    "  - Enables concatenation into unified structure\n",
    "\n",
    "### Padding Information Tracking\n",
    "The decoder now tracks:\n",
    "- Original width of each burst\n",
    "- Whether padding was applied\n",
    "- Amount of padding added\n",
    "- Final unified width\n",
    "\n",
    "This ensures full traceability of any modifications made to the original data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarpyx-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
