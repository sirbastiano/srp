{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca2ad74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files in /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/data:\n",
      " - S1A_S1_RAW__0SDH_20240502T121147_20240502T121217_053692_06859D_BB61.SAFE\n",
      " - S1A_S3_RAW__0SDH_20240430T213606_20240430T213631_053668_0684A3_8760.SAFE\n",
      " - S1A_S4_RAW__0SDV_20240502T193657_20240502T193727_053696_0685CA_DEE6.SAFE\n",
      " - S1A_S2_RAW__0SDV_20240502T014919_20240502T014940_053686_068553_FB9C.SAFE\n",
      " - S1A_S5_RAW__0SDV_20240429T200803_20240429T200833_053653_068410_92A9.SAFE\n",
      " - S1A_S6_RAW__0SDV_20240502T195132_20240502T195153_053697_0685CC_E173.SAFE\n",
      "\n",
      "\n",
      "Input file: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/data/S1A_S1_RAW__0SDH_20240502T121147_20240502T121217_053692_06859D_BB61.SAFE/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d.dat\n"
     ]
    }
   ],
   "source": [
    "from sarpyx.processor.core.decode import S1L0Decoder\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "def decode_and_save(\n",
    "    input_file: Path | str,\n",
    "    output_dir: Path | str,\n",
    "    headers_only: bool = False,\n",
    "    log_level: int = logging.INFO\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Convenience function to decode and save a Sentinel-1 Level 0 file.\n",
    "\n",
    "    Args:\n",
    "        input_file (Path | str): Path to the input .dat file.\n",
    "        output_dir (Path | str): Directory to save processed data.\n",
    "        headers_only (bool): If True, extract only headers for quick preview.\n",
    "        log_level (int): Logging level.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary containing processing results and file paths.\n",
    "\n",
    "    Example:\n",
    "        >>> result = decode_and_save(\n",
    "        ...     'data.dat',\n",
    "        ...     'output/',\n",
    "        ...     headers_only=True\n",
    "        ... )\n",
    "        >>> print(f\"Processed {result['num_records']} records\")\n",
    "    \"\"\"\n",
    "    decoder = S1L0Decoder(log_level=log_level)\n",
    "    return decoder.decode_file(input_file, output_dir, headers_only)\n",
    "\n",
    "\n",
    "def find_dat_file(folder: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Find the .dat file in a folder, excluding annotation or index files.\n",
    "\n",
    "    Args:\n",
    "        folder (Path): The folder to search in.\n",
    "\n",
    "    Returns:\n",
    "        Path: The path to the .dat file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If no valid .dat file is found.\n",
    "        AssertionError: If the provided path is not a directory.\n",
    "    \"\"\"\n",
    "    assert folder.exists(), f'The provided path {folder} does not exist.'\n",
    "    assert folder.is_dir(), f'The provided path {folder} is not a directory.'\n",
    "\n",
    "    for file in folder.iterdir():\n",
    "        if file.suffix == '.dat' and 'annot' not in file.name and 'index' not in file.name and 'hh' in file.name:\n",
    "            return file\n",
    "\n",
    "    raise FileNotFoundError(f'No valid .dat file found in {folder}.')\n",
    "\n",
    "cwd: Path = Path.cwd().parent\n",
    "\n",
    "data_dir: Path = cwd / 'data'\n",
    "\n",
    "files_names = list(data_dir.iterdir())\n",
    "print(f'Available files in {data_dir}:')\n",
    "for file in files_names:\n",
    "    print(f' - {file.name}')\n",
    "\n",
    "\n",
    "file_name: str = files_names[0].name if files_names else ''\n",
    "if not file_name:\n",
    "    raise FileNotFoundError('No files found in the data directory.')\n",
    "safe_folder: Path = data_dir / file_name\n",
    "\n",
    "assert safe_folder.exists(), f'The SAFE folder {safe_folder} does not exist.'\n",
    "assert safe_folder.is_dir(), f'The SAFE folder {safe_folder} is not a directory.'\n",
    "\n",
    "input_file: Path = find_dat_file(safe_folder)\n",
    "print(f'\\n\\nInput file: {input_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53959888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 13:12:31,081 - INFO - Processing file: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/data/S1A_S1_RAW__0SDH_20240502T121147_20240502T121217_053692_06859D_BB61.SAFE/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d.dat\n",
      "2025-06-03 13:12:31,082 - INFO - File size: 954.2 MB\n",
      "2025-06-03 13:12:31,082 - INFO - Starting full decode process...\n",
      "2025-06-03 13:12:31,083 - INFO - Starting decode process for: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/data/S1A_S1_RAW__0SDH_20240502T121147_20240502T121217_053692_06859D_BB61.SAFE/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d.dat\n",
      "decoded: 56946 packets [01:08, 828.93 packets/s]\n",
      "2025-06-03 13:13:39,783 - INFO - Decoded 56946 records from file\n",
      "2025-06-03 13:13:39,784 - WARNING - Incomplete sub-commutated data cycle: 24\n",
      "2025-06-03 13:13:39,785 - WARNING - Incomplete sub-commutated data cycle: 54\n",
      "2025-06-03 13:13:39,785 - WARNING - Incomplete sub-commutated data cycle: 83\n",
      "2025-06-03 13:13:39,786 - WARNING - Incomplete sub-commutated data cycle: 113\n",
      "2025-06-03 13:13:39,787 - WARNING - Incomplete sub-commutated data cycle: 143\n",
      "2025-06-03 13:13:39,788 - WARNING - Incomplete sub-commutated data cycle: 173\n",
      "2025-06-03 13:13:39,789 - WARNING - Incomplete sub-commutated data cycle: 203\n",
      "2025-06-03 13:13:39,789 - WARNING - Incomplete sub-commutated data cycle: 233\n",
      "2025-06-03 13:13:39,790 - WARNING - Incomplete sub-commutated data cycle: 263\n",
      "2025-06-03 13:13:39,791 - WARNING - Incomplete sub-commutated data cycle: 293\n",
      "2025-06-03 13:13:39,792 - WARNING - Incomplete sub-commutated data cycle: 323\n",
      "2025-06-03 13:13:39,793 - WARNING - Incomplete sub-commutated data cycle: 353\n",
      "2025-06-03 13:13:39,793 - WARNING - Incomplete sub-commutated data cycle: 383\n",
      "2025-06-03 13:13:39,794 - WARNING - Incomplete sub-commutated data cycle: 413\n",
      "2025-06-03 13:13:39,795 - WARNING - Incomplete sub-commutated data cycle: 443\n",
      "2025-06-03 13:13:39,796 - WARNING - Incomplete sub-commutated data cycle: 473\n",
      "2025-06-03 13:13:39,797 - WARNING - Incomplete sub-commutated data cycle: 503\n",
      "2025-06-03 13:13:39,798 - WARNING - Incomplete sub-commutated data cycle: 533\n",
      "2025-06-03 13:13:39,800 - WARNING - Incomplete sub-commutated data cycle: 592\n",
      "2025-06-03 13:13:39,801 - WARNING - Incomplete sub-commutated data cycle: 622\n",
      "2025-06-03 13:13:39,801 - WARNING - Incomplete sub-commutated data cycle: 652\n",
      "2025-06-03 13:13:39,802 - WARNING - Incomplete sub-commutated data cycle: 682\n",
      "2025-06-03 13:13:39,803 - WARNING - Incomplete sub-commutated data cycle: 712\n",
      "2025-06-03 13:13:39,804 - WARNING - Incomplete sub-commutated data cycle: 742\n",
      "2025-06-03 13:13:39,804 - WARNING - Incomplete sub-commutated data cycle: 772\n",
      "2025-06-03 13:13:39,805 - WARNING - Incomplete sub-commutated data cycle: 802\n",
      "2025-06-03 13:13:39,806 - WARNING - Incomplete sub-commutated data cycle: 832\n",
      "2025-06-03 13:13:39,807 - WARNING - Incomplete sub-commutated data cycle: 862\n",
      "2025-06-03 13:13:39,808 - WARNING - Incomplete sub-commutated data cycle: 892\n",
      "2025-06-03 13:13:39,808 - WARNING - Incomplete sub-commutated data cycle: 910\n",
      "2025-06-03 13:13:39,809 - INFO - 911 sub-commutated data cycles collected.\n",
      "2025-06-03 13:13:39,823 - INFO - 30 incomplete sub-commutated data cycles.\n",
      "2025-06-03 13:13:39,840 - INFO - Extracted ephemeris data with 881 records\n",
      "2025-06-03 13:13:39,853 - INFO - Extracted 1 echo bursts\n",
      "2025-06-03 13:13:45,932 - INFO - Processed burst 0: (56130, 25724) radar samples, 56130 metadata records\n",
      "2025-06-03 13:13:46,405 - INFO - Successfully decoded 1 bursts\n",
      "2025-06-03 13:13:46,407 - INFO - Saving processed data to: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/processed_data\n",
      "2025-06-03 13:13:46,411 - INFO - Saved ephemeris: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/processed_data/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d_ephemeris.pkl\n",
      "2025-06-03 13:13:56,557 - INFO - Successfully saved pickle file: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/processed_data/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d_burst_0_echo.pkl\n",
      "2025-06-03 13:13:56,559 - INFO - Saved burst 0: metadata and echo data\n",
      "2025-06-03 13:13:56,561 - INFO - Successfully saved pickle file: /Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/processed_data/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d_info.pkl\n",
      "2025-06-03 13:13:56,561 - INFO - Created 4 output files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================  Processed. ==================================================\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_path = cwd / 'processed_data'\n",
    "if not folder_path.exists():\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if input_file:\n",
    "    result = decode_and_save(\n",
    "        input_file=input_file,\n",
    "        output_dir=folder_path,\n",
    "        headers_only=False,\n",
    "        log_level=logging.INFO\n",
    "    )\n",
    "    print(\"\\n\", 50*\"=\", f\" Processed.\", 50*\"=\")\n",
    "else:\n",
    "    print('\\n\\n No .dat file found in the specified folder.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00f133c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# load the processed data\u001b[39;00m\n\u001b[32m      4\u001b[39m processed_data = joblib.load(\u001b[33m\"\u001b[39m\u001b[33m/Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/processed_data/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d_burst_0_echo.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "# load the processed data\n",
    "processed_data = joblib.load(\"/Users/roberto.delprete/Library/CloudStorage/OneDrive-ESA/Desktop/Repos/SARPYX/processed_data/s1a-s1-raw-s-hh-20240502t121147-20240502t121217-053692-06859d_burst_0_echo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bbe4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
