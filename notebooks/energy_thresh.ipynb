{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def edic_features(image, window_size=5, transform=np.log):\n",
    "    \"\"\"\n",
    "    Compute EDIC features F1 and F2 on a SAR image using a sliding window approach.\n",
    "\n",
    "    For each n x n window G(i,j) (with stride 1) whose center is at (i,j):\n",
    "      1. Compute the singular values {s1, s2, ..., s_n} via SVD.\n",
    "      2. Feature F1 is defined as:\n",
    "             F1(i,j) = s1 - s2\n",
    "      3. Feature F2 is defined as:\n",
    "             F2(i,j) = f( s1 / (sum(s2...s_n) + ε) )\n",
    "         where f(·) is a transformation function (e.g. logarithm) and ε is a small constant\n",
    "         to avoid division by zero.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.ndarray): 2D SAR image.\n",
    "        window_size (int): Size of the square sliding window (default: 5).\n",
    "        transform (function): Transformation function applied to the ratio in F2 (default: np.log).\n",
    "\n",
    "    Returns:\n",
    "        F1 (np.ndarray): Feature image computed from the difference s1-s2.\n",
    "        F2 (np.ndarray): Feature image computed from the transformed ratio.\n",
    "                         Both output images have shape (rows - window_size + 1, cols - window_size + 1).\n",
    "    \"\"\"\n",
    "    rows, cols = image.shape\n",
    "    out_rows = rows - window_size + 1\n",
    "    out_cols = cols - window_size + 1\n",
    "\n",
    "    F1 = np.zeros((out_rows, out_cols))\n",
    "    F2 = np.zeros((out_rows, out_cols))\n",
    "    eps = 1e-8  # small constant to prevent division by zero\n",
    "\n",
    "    # Slide over the image with a stride of 1 (valid windows only)\n",
    "    for i in range(out_rows):\n",
    "        for j in range(out_cols):\n",
    "            # Extract the local n×n window\n",
    "            window = image[i:i+window_size, j:j+window_size]\n",
    "            # Compute the singular values; they are returned in descending order\n",
    "            singular_values = np.linalg.svd(window, compute_uv=False)\n",
    "            \n",
    "            # F1: Difference between the first and second singular values\n",
    "            F1[i, j] = singular_values[0] - singular_values[1]\n",
    "            \n",
    "            # F2: Apply the transformation function to the ratio s1/(sum(s2...s_n))\n",
    "            ratio = singular_values[0] / (np.sum(singular_values[1:]) + eps)\n",
    "            F2[i, j] = transform(ratio)\n",
    "            \n",
    "    return F1, F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def edic_features_torch(image: torch.Tensor, window_size: int = 5, transform: callable = torch.log) -> tuple:\n",
    "    \"\"\"\n",
    "    Compute EDIC features F1 and F2 on a SAR image using a sliding window approach with PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "        image (torch.Tensor): 2D SAR image (tensor of shape [H, W]).\n",
    "        window_size (int): Size of the square sliding window (default: 5).\n",
    "        transform (callable): Transformation function applied to the ratio in F2 (default: torch.log).\n",
    "\n",
    "    Returns:\n",
    "        F1 (torch.Tensor): Feature image computed from the difference s1-s2.\n",
    "        F2 (torch.Tensor): Feature image computed from the transformed ratio.\n",
    "    \"\"\"\n",
    "    \n",
    "    cuda_flag = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda_flag else \"cpu\")\n",
    "    image = image.to(device)\n",
    "    \n",
    "    eps = 1e-8  # Small constant to prevent division by zero\n",
    "    pad = window_size // 2\n",
    "    H, W = image.shape\n",
    "\n",
    "    # Unfold the image into sliding windows\n",
    "    unfolded = F.unfold(image.unsqueeze(0).unsqueeze(0), kernel_size=window_size).squeeze(0)\n",
    "    \n",
    "    # Reshape to (num_windows, window_size, window_size)\n",
    "    num_patches = unfolded.shape[1]\n",
    "    unfolded = unfolded.T.view(num_patches, window_size, window_size)\n",
    "\n",
    "    # Compute singular values using SVD\n",
    "    U, S, V = torch.svd(unfolded.view(num_patches, window_size, window_size))\n",
    "\n",
    "    # Compute F1 and F2\n",
    "    F1 = S[:, 0] - S[:, 1]\n",
    "    ratio = S[:, 0] / (S[:, 1:].sum(dim=1) + eps)\n",
    "    F2 = transform(ratio)\n",
    "\n",
    "    # Reshape to output spatial dimensions\n",
    "    out_H, out_W = H - window_size + 1, W - window_size + 1\n",
    "    F1 = F1.view(out_H, out_W)\n",
    "    F2 = F2.view(out_H, out_W)\n",
    "\n",
    "\n",
    "    F1 = F1.cpu()\n",
    "    F2 = F2.cpu()\n",
    "    # return as numpy arrays\n",
    "    return F1.numpy(), F2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_complex_image_and_features(image, window_size=5, transform=np.log):\n",
    "    \"\"\"\n",
    "    Plot the complex image, F1, and F2 in a 1x3 graph.\n",
    "\n",
    "    Parameters:\n",
    "        image (np.ndarray): 2D complex image.\n",
    "        window_size (int): Size of the square sliding window (default: 5).\n",
    "        transform (function): Transformation function applied to the ratio in F2 (default: np.log).\n",
    "    \"\"\"\n",
    "    # Compute EDIC features\n",
    "    F1, F2 = edic_features(image, window_size, transform)\n",
    "    \n",
    "    # Create a 1x3 subplot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot the complex image\n",
    "    axes[0].imshow(np.abs(image), cmap='gray')\n",
    "    axes[0].set_title('Complex Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Plot F1\n",
    "    axes[1].imshow(F1, cmap='jet')\n",
    "    axes[1].set_title('Feature F1')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Plot F2\n",
    "    axes[2].imshow(F2, cmap='jet')\n",
    "    axes[2].set_title('Feature F2')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Show the plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pickle file from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NumPy array from a pickle file\n",
    "file_path = '/Data_large/marine/PythonProjects/RFI_project/Data/Data_raw_decoded/S1B_IW_RAW__0SDV_20200116T054832_20200116T054904_019838_02582D_2BD3.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    array = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacke the decoded IWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def iw_extraction(decoded_prod, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract the IWs from the echo data.\n",
    "\n",
    "    Parameters:\n",
    "        decoded_prod (dict): Dictionary containing the echo data.\n",
    "        verbose (bool): Print the number of lines for each rg_len (default: False).\n",
    "\n",
    "    Returns:\n",
    "        IWs (dict): Dictionary containing the IWs grouped by rg_len.\n",
    "    \"\"\"\n",
    "    # Extract the echo data\n",
    "    # Ensure the input dictionary contains the required keys\n",
    "    assert 'echo' in decoded_prod, \"The input dictionary must contain the key 'echo'.\"\n",
    "    assert 'metadata' in decoded_prod, \"The input dictionary must contain the key 'metadata'.\"\n",
    "    \n",
    "    echo = decoded_prod[\"echo\"]\n",
    "    metadata = decoded_prod[\"metadata\"]\n",
    "    \n",
    "    # Ensure echo and metadata have the same length\n",
    "    assert len(echo) == len(metadata), \"The length of 'echo' and 'metadata' must be the same.\"\n",
    "    \n",
    "    # Group the lines based on the rg_len\n",
    "    IWs = defaultdict(list)\n",
    "    SubComm = defaultdict(list)\n",
    "    for line, metaline in tqdm(zip(echo, metadata.itertuples(index=False)), total=len(echo), desc=\"Extracting IWs\"):\n",
    "        rg_len = len(line)\n",
    "        IWs[rg_len].append(line)\n",
    "        SubComm[rg_len].append(metaline._asdict())\n",
    "\n",
    "    if verbose:\n",
    "        # Print the grouped lines\n",
    "        for rg_len, lines in IWs.items():\n",
    "            print(f\"rg_len: {rg_len}, number of lines: {len(lines)}\")\n",
    "        # Print the keys of the metadata\n",
    "        print(metadata.columns)\n",
    "\n",
    "    # Collect into a unique dictionary\n",
    "    Bursts_dict = {}\n",
    "    for key in tqdm(IWs.keys(), desc=\"Converting to arrays:\"):\n",
    "        Bursts_dict[key] = dict(echo=np.array(IWs[key]), metadata=pd.DataFrame(SubComm[key]))\n",
    "\n",
    "    return Bursts_dict\n",
    "\n",
    "\n",
    "def plot_feature(feature, title):\n",
    "    \"\"\"\n",
    "    Plot a feature matrix (F1 or F2).\n",
    "\n",
    "    Parameters:\n",
    "        feature (np.ndarray): 2D feature matrix to plot.\n",
    "        title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    plt.imshow(feature, cmap='jet')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts = iw_extraction(array, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bursts[19722][\"echo\"]\n",
    "\n",
    "sel = 0\n",
    "sub_img = img[500:1000, :10000]\n",
    "print(sub_img.shape)\n",
    "\n",
    "\n",
    "F1, F2 = edic_features_torch(torch.tensor(sub_img), window_size=5, transform=torch.log)\n",
    "\n",
    "plot_feature(F1, 'Feature F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature(F2, 'Feature F2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "# Assuming sqdT is equivalent to filtered_data and RadPar.fs is the sampling frequency\n",
    "sampling_frequency = 300e6  # 300 MHz\n",
    "\n",
    "filtered_data = sub_img\n",
    "\n",
    "\n",
    "# Compute the power spectral density\n",
    "frequencies, psd = welch(filtered_data.flatten(), nperseg=filtered_data.shape[0], noverlap=None, nfft=filtered_data.shape[1], fs=sampling_frequency, return_onesided=False)\n",
    "\n",
    "# Shift the zero frequency component to the center\n",
    "frequencies = np.fft.fftshift(frequencies)\n",
    "psd = np.fft.fftshift(psd)\n",
    "\n",
    "# Plot the power spectral density\n",
    "plt.figure(figsize=(14, 14), dpi=120)\n",
    "plt.plot(frequencies, 10 * np.log10(psd))\n",
    "plt.title('Power Spectral Density of Filtered Data (dB)')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('dB')\n",
    "plt.gca()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_filtered_data = np.fft.fft(filtered_data, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 5), dpi=120)\n",
    "plt.imshow(np.abs(fft_filtered_data), aspect='auto', cmap='jet', extent=[frequencies[0], frequencies[-1], 0, fft_filtered_data.shape[0]])\n",
    "plt.title('FFT of Filtered Data')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW PATCH WITH RFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bursts[19722][\"echo\"]\n",
    "\n",
    "sub_img = img[10000:11000, :]\n",
    "\n",
    "\n",
    "plot_feature(np.abs(sub_img), 'img')\n",
    "\n",
    "F1, F2 = edic_features_torch(torch.tensor(sub_img), window_size=5, transform=torch.log)\n",
    "\n",
    "# plot_feature(F1, 'Feature F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "# Assuming sqdT is equivalent to filtered_data and RadPar.fs is the sampling frequency\n",
    "sampling_frequency = 300e6  # 300 MHz\n",
    "\n",
    "filtered_data = sub_img\n",
    "\n",
    "# Compute the power spectral density\n",
    "frequencies, psd = welch(filtered_data.flatten(), nperseg=filtered_data.shape[0], noverlap=None, nfft=filtered_data.shape[1], fs=sampling_frequency, return_onesided=False)\n",
    "\n",
    "# Shift the zero frequency component to the center\n",
    "frequencies = np.fft.fftshift(frequencies)\n",
    "psd = np.fft.fftshift(psd)\n",
    "\n",
    "# Plot the power spectral density\n",
    "plt.figure(figsize=(14, 4), dpi=120)\n",
    "plt.plot(frequencies, 10 * np.log10(psd))\n",
    "plt.title('Power Spectral Density of Filtered Data (dB)')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('dB')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0f}'))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_filtered_data = np.fft.fft(filtered_data, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 5), dpi=120)\n",
    "plt.imshow(np.abs(fft_filtered_data), aspect='auto', cmap='jet', extent=[frequencies[0], frequencies[-1], 0, fft_filtered_data.shape[0]])\n",
    "plt.title('FFT of Filtered Data')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define the frequency range for the plot\n",
    "# freq_range = (frequencies >= 10e6) & (frequencies <= 50e6)\n",
    "\n",
    "# # Plot the FFT of filtered data within the specified frequency range\n",
    "# plt.figure(figsize=(15, 5), dpi=120)\n",
    "# plt.imshow(np.abs(fft_filtered_data[:, freq_range]), aspect='auto', cmap='jet', extent=[frequencies[freq_range][0], frequencies[freq_range][-1], 0, fft_filtered_data.shape[0]])\n",
    "# plt.title('FFT of Filtered Data (10 MHz to 50 MHz)')\n",
    "# plt.xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Magnitude')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_complex_image_and_features(sub_img, window_size=5, transform=np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold values\n",
    "threshold_value1 = np.mean(F1) + 3 * np.std(F1)\n",
    "threshold_value2 = np.mean(F2) + 3 * np.std(F2)\n",
    "\n",
    "# Create a segmentation mask based on the threshold\n",
    "segmentation_mask1 = F1 > threshold_value1\n",
    "segmentation_mask2 = F2 > threshold_value2\n",
    "\n",
    "\n",
    "# segmentation mask is considered wwhen both F1 and F2 are above the threshold\n",
    "segmentation_mask = segmentation_mask1 & segmentation_mask2\n",
    "\n",
    "# Plot the segmentation mask\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(segmentation_mask1, cmap='gray')\n",
    "plt.title('Segmentation Mask1')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the segmentation mask\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(segmentation_mask2, cmap='gray')\n",
    "plt.title('Segmentation Mask2')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot the segmentation mask\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(segmentation_mask, cmap='gray')\n",
    "plt.title('Segmentation Mask')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "# Remove small objects from the segmentation mask\n",
    "cleaned_segmentation_mask = remove_small_objects(segmentation_mask, min_size=75)\n",
    "\n",
    "# Plot the cleaned segmentation mask\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cleaned_segmentation_mask[:,:4000], cmap='gray')\n",
    "plt.title('Cleaned Segmentation Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
