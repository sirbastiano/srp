{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download, snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "def download_hf_dataset(repo_id: str, folder_name: str, local_dir: str = None) -> Path:\n",
    "    \"\"\"\n",
    "    Download a folder from Hugging Face Hub dataset.\n",
    "\n",
    "    Args:\n",
    "        repo_id (str): Repository ID (e.g., 'sirbastiano94/Maya4').\n",
    "        folder_name (str): Specific folder to download.\n",
    "        local_dir (str, optional): Local directory to save the data (defaults to folder_name).\n",
    "\n",
    "    Returns:\n",
    "        Path: Path to the downloaded folder.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If download fails.\n",
    "    \"\"\"\n",
    "    local_path = Path(local_dir or folder_name)\n",
    "    print(f'Downloading {folder_name} from {repo_id} to {local_path}...')\n",
    "    try:\n",
    "        snapshot_download(\n",
    "            repo_id=repo_id,\n",
    "            repo_type='dataset',\n",
    "            local_dir=str(local_path),\n",
    "            allow_patterns=[f'{folder_name}/**'],\n",
    "            max_workers=10,\n",
    "            resume_download=True,\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        assert local_path.exists(), f'Directory {local_path} not found after download'\n",
    "        print(f'Successfully downloaded {folder_name} to {local_path}')\n",
    "        print('Downloaded files:')\n",
    "        for root, dirs, files in os.walk(local_path):\n",
    "            level = root.replace(str(local_path), '').count(os.sep)\n",
    "            indent = ' ' * 2 * level\n",
    "            print(f'{indent}{os.path.basename(root)}/')\n",
    "            for f in files:\n",
    "                print(f'{indent}  {f}')\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        print(f'Download failed: {e}')\n",
    "        raise\n",
    "\n",
    "# Usage\n",
    "repo_id = 'sirbastiano94/Maya4'\n",
    "folder_name = 's1a-s1-raw-s-hh-20240130t151239-20240130t151254-052337-06541b.zarr' #'s1a-s1-raw-s-hh-20230508t121142-20230508t121213-048442-05d3c0.zarr'\n",
    "downloaded_path = download_hf_dataset(repo_id, folder_name, local_dir='/Data/sar_focusing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9f1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "sys.path.append(os.path.abspath((os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_sar_dataloader\n",
    "\n",
    "\n",
    "loader = get_sar_dataloader(\n",
    "    data_dir=\"/Data/sar_focusing\",\n",
    "    level_from=\"rc\",\n",
    "    level_to=\"az\",\n",
    "    batch_size=16,\n",
    "    num_workers=0,\n",
    "    patch_mode=\"square\", \n",
    "    patch_size = (1, 1000),\n",
    "    buffer = (1000, 1000),\n",
    "    stride = (1, 1000),\n",
    "    shuffle_files = False,\n",
    "    shuffle_patches = False, \n",
    "    complex_valued = True,\n",
    "    save_samples = False, \n",
    "    backend=\"zarr\", \n",
    "    verbose=True, \n",
    "    k = 1000,\n",
    "    cache_size = 1000, \n",
    "    online = True\n",
    ")\n",
    "for i, (x_batch, y_batch) in enumerate(loader):\n",
    "    print(f\"Batch {i}: x {x_batch.shape}, y {y_batch.shape}\")\n",
    "\n",
    "# patch calculation + patch extraction - 7.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import fetch_chunk_from_hf_zarr\n",
    "\n",
    "fetch_chunk_from_hf_zarr(\n",
    "    level='az',\n",
    "    zarr_archive=\"s1a-s1-raw-s-hh-20230731t121147-20230731t121217-049667-05f8f1.zarr\",\n",
    "    y=7000,\n",
    "    x=15000,\n",
    "    local_dir=\"/Data/sar_focusing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f4478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "store = zarr.open(\n",
    "    \"/Data/sar_focusing/s1a-s1-raw-s-hh-20240130t151239-20240130t151254-052337-06541b.zarr\", #s1a-s1-raw-s-hh-20230731t121147-20230731t121217-049667-05f8f1.zarr\", #s1a-s1-raw-s-hh-20240130t151239-20240130t151254-052337-06541b_bis.zarr/s1a-s1-raw-s-hh-20240130t151239-20240130t151254-052337-06541b.zarr\",\n",
    "    mode='r'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "store['az'][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
