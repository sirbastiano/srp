{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/gdaga/anaconda3/envs/sar_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:training_script:Configuration Summary:\n",
      "INFO:training_script:  Data directory: /Data/sar_focusing\n",
      "INFO:training_script:  Level from: rcmc\n",
      "INFO:training_script:  Level to: az\n",
      "INFO:training_script:  Patch size: [1000, 1]\n",
      "INFO:training_script:  Batch size: 64\n",
      "INFO:training_script:  Save directory: ./visualizations\n",
      "INFO:training_script:Creating test dataloader...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': '/Data/sar_focusing', 'epochs': 200, 'lr': '1e-3', 'model': {'name': 'rv_transformer', 'seq_len': 1000, 'input_dim': 2000, 'model_dim': 1024, 'num_layers': 4, 'num_heads': 4, 'ff_dim': 256, 'dropout': 0.1, 'dim_head': 16, 'mode': 'autoregressive', 'dim': 1024, 'depth': 4, 'heads': 4, 'ff_mult': 1}, 'training': {'patience': 20, 'delta': 0.001, 'mode': 'autoregressive', 'device': 'cuda', 'batch_size': 64, 'learning_rate': 0.0001, 'num_epochs': 50, 'save_dir': './visualizations'}, 'dataloader': {'level_from': 'rcmc', 'level_to': 'az', 'num_workers': 0, 'patch_mode': 'rectangular', 'patch_size': [1000, 1], 'buffer': [1000, 1000], 'stride': [300, 1], 'shuffle_files': False, 'complex_valued': False, 'save_samples': False, 'backend': 'zarr', 'verbose': False, 'cache_size': 1000, 'online': True, 'concatenate_patches': True, 'concat_axis': 0, 'positional_encoding': True, 'train': {'batch_size': 64, 'samples_per_prod': 1, 'patch_order': 'row', 'max_products': 1, 'pattern': '*2023*.zarr'}, 'validation': {'batch_size': 64, 'samples_per_prod': 1000, 'patch_order': 'row', 'max_products': 1, 'pattern': '*2024*.zarr'}, 'test': {'batch_size': 64, 'samples_per_prod': 5000, 'patch_order': 'row', 'max_products': 1, 'pattern': '*2025*.zarr'}, 'data_dir': '/Data/sar_focusing', 'transforms': {'normalize': True, 'rc_min': -3000.0, 'rc_max': 3000.0, 'gt_min': -12000.0, 'gt_max': 12000.0}}, 'transforms': {'normalize': True, 'rc_min': -3000.0, 'rc_max': 3000.0, 'gt_min': -12000.0, 'gt_max': 12000.0}, 'device': 'cuda', 'base_save_dir': './results/rv_autoregressive', 'save_results': True}\n",
      "Creating dataloader with config: {'data_dir': '/Data/sar_focusing', 'level_from': 'rcmc', 'level_to': 'az', 'num_workers': 0, 'patch_mode': 'rectangular', 'patch_size': (1000, 1), 'buffer': (1000, 1000), 'stride': (300, 1), 'shuffle_files': False, 'complex_valued': False, 'save_samples': False, 'backend': 'zarr', 'verbose': False, 'cache_size': 1000, 'online': True, 'concatenate_patches': True, 'concat_axis': 0, 'positional_encoding': True, 'transform': None, 'batch_size': 64, 'samples_per_prod': 5000, 'patch_order': 'row', 'max_products': 1, 'file_pattern': '*2025*.zarr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training_script:Created test dataloader with 0 batches\n",
      "INFO:training_script:Dataset contains 5000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from: /Data/gdaga/sarpyx_new/sarpyx/training/../results/rv_autoregressive/sar_transformer_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training_script:Starting sample visualization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 125 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:training_script:Visualization failed with error: TrainerBase.forward_pass() missing 2 required positional arguments: 'y' and 'device'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainerBase.forward_pass() missing 2 required positional arguments: 'y' and 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 157\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    156\u001b[39m     inference_fn = get_training_loop_by_model_name(\u001b[33m\"\u001b[39m\u001b[33mrv_transformer_autoregressive\u001b[39m\u001b[33m\"\u001b[39m, model=model, save_dir=save_dir, mode=args.mode, loss_fn_name=\u001b[33m\"\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m\"\u001b[39m).forward_pass\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     gt, pred, \u001b[38;5;28minput\u001b[39m = \u001b[43mget_full_image_and_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzfile\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_prod\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_samples_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     display_inference_results(\n\u001b[32m    165\u001b[39m         input_data=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    166\u001b[39m         gt_data=gt,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m         vminmax=(\u001b[32m0\u001b[39m, \u001b[32m1000\u001b[39m)  \u001b[38;5;66;03m# Adjust this range based on your data\u001b[39;00m\n\u001b[32m    170\u001b[39m     )\n\u001b[32m    172\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mVisualization completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Data/gdaga/sarpyx_new/sarpyx/training/visualize.py:151\u001b[39m, in \u001b[36mget_full_image_and_prediction\u001b[39m\u001b[34m(dataset, zfile, inference_fn, max_samples_per_prod, batch_size, return_input, vminmax)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(input_patches), batch_size):\n\u001b[32m    149\u001b[39m     batch = input_patches[i:i+batch_size]\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     pred = \u001b[43minference_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Should return (B, ph, pw) or (B, ph, pw, ...)\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, torch.Tensor):\n\u001b[32m    153\u001b[39m         pred = pred.detach().cpu().numpy()\n",
      "\u001b[31mTypeError\u001b[39m: TrainerBase.forward_pass() missing 2 required positional arguments: 'y' and 'device'"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os \n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import yaml\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader.dataloader import get_sar_dataloader, SARTransform\n",
    "from model.model_utils import get_model_from_configs, create_model_with_pretrained\n",
    "from training.training_loops import get_training_loop_by_model_name\n",
    "from training.visualize import save_results_and_metrics, get_full_image_and_prediction\n",
    "from sarpyx.utils.losses import get_loss_function\n",
    "from training_script import setup_logging, load_config\n",
    "from inference_script import create_test_dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def display_inference_results(input_data, gt_data, pred_data, figsize=(20, 6), vminmax=(0, 1000)):\n",
    "    \"\"\"\n",
    "    Display input, ground truth, and prediction in a 3-column grid.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Input data from the dataset\n",
    "        gt_data: Ground truth data\n",
    "        pred_data: Model prediction\n",
    "        figsize: Figure size\n",
    "        vminmax: Value range for visualization\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy if needed\n",
    "    if hasattr(input_data, 'numpy'):\n",
    "        input_data = input_data.cpu().numpy()\n",
    "    if hasattr(gt_data, 'numpy'):\n",
    "        gt_data = gt_data.cpu().numpy()\n",
    "    if hasattr(pred_data, 'numpy'):\n",
    "        pred_data = pred_data.cpu().numpy()\n",
    "    \n",
    "    # Function to get magnitude visualization (similar to get_sample_visualization)\n",
    "    def get_magnitude_vis(data, vminmax):\n",
    "        if np.iscomplexobj(data):\n",
    "            magnitude = np.abs(data)\n",
    "        else:\n",
    "            magnitude = data\n",
    "        \n",
    "        if vminmax == 'auto':\n",
    "            vmin, vmax = np.percentile(magnitude, [2, 98])\n",
    "        elif isinstance(vminmax, tuple):\n",
    "            vmin, vmax = vminmax\n",
    "        else:\n",
    "            vmin, vmax = np.min(magnitude), np.max(magnitude)\n",
    "        \n",
    "        return magnitude, vmin, vmax\n",
    "    \n",
    "    # Prepare visualizations\n",
    "    imgs = []\n",
    "    \n",
    "    # Input data\n",
    "    img, vmin, vmax = get_magnitude_vis(input_data, vminmax)\n",
    "    imgs.append({'name': 'Input (RCMC)', 'img': img, 'vmin': vmin, 'vmax': vmax})\n",
    "    \n",
    "    # Ground truth\n",
    "    img, vmin, vmax = get_magnitude_vis(gt_data, vminmax)\n",
    "    imgs.append({'name': 'Ground Truth (AZ)', 'img': img, 'vmin': vmin, 'vmax': vmax})\n",
    "    \n",
    "    # Prediction\n",
    "    img, vmin, vmax = get_magnitude_vis(pred_data, vminmax)\n",
    "    imgs.append({'name': 'Prediction (AZ)', 'img': img, 'vmin': vmin, 'vmax': vmax})\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    \n",
    "    for i in range(3):\n",
    "        im = axes[i].imshow(\n",
    "            imgs[i]['img'],\n",
    "            aspect='auto',\n",
    "            cmap='viridis',\n",
    "            vmin=imgs[i]['vmin'],\n",
    "            vmax=imgs[i]['vmax']\n",
    "        )\n",
    "        \n",
    "        axes[i].set_title(f\"{imgs[i]['name']}\")\n",
    "        axes[i].set_xlabel('Range')\n",
    "        axes[i].set_ylabel('Azimuth')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "        \n",
    "        # Set equal aspect ratio\n",
    "        axes[i].set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    config=\"rv_transformer_autoregressive.yaml\",\n",
    "    device=\"cuda\", \n",
    "    batch_size=64,\n",
    "    save_dir=\"./visualizations\",\n",
    "    max_batches=64,\n",
    "    max_samples_per_batch=4,\n",
    "    mode=\"autoregressive\",\n",
    "    pretrained_path=os.path.join(os.getcwd(), '..', 'results', 'rv_autoregressive','sar_transformer_best.pth'), \n",
    "    learning_rate=1e-4, \n",
    "    num_epochs=50\n",
    ")\n",
    "\n",
    "# # Setup logging\n",
    "logger = setup_logging()\n",
    "#logger.info(f\"Starting visualization with config: {args.config}\")\n",
    "\n",
    "# Load configuration\n",
    "config = load_config(Path(args.config), args)\n",
    "\n",
    "# Extract configurations\n",
    "dataloader_cfg = config['dataloader']\n",
    "training_cfg = config.get('training', {})\n",
    "\n",
    "# Override save directory\n",
    "save_dir = args.save_dir or training_cfg.get('save_dir', './visualizations')\n",
    "\n",
    "# Log configuration summary\n",
    "logger.info(\"Configuration Summary:\")\n",
    "logger.info(f\"  Data directory: {dataloader_cfg.get('data_dir', 'Not specified')}\")\n",
    "logger.info(f\"  Level from: {dataloader_cfg.get('level_from', 'rcmc')}\")\n",
    "logger.info(f\"  Level to: {dataloader_cfg.get('level_to', 'az')}\")\n",
    "logger.info(f\"  Patch size: {dataloader_cfg.get('patch_size', [1000, 1])}\")\n",
    "logger.info(f\"  Batch size: {dataloader_cfg.get('test', {}).get('batch_size', 'Not specified')}\")\n",
    "logger.info(f\"  Save directory: {save_dir}\")\n",
    "\n",
    "# Create test dataloader\n",
    "logger.info(\"Creating test dataloader...\")\n",
    "try:\n",
    "    test_loader = create_test_dataloader(dataloader_cfg)\n",
    "    logger.info(f\"Created test dataloader with {len(test_loader)} batches\")\n",
    "    logger.info(f\"Dataset contains {len(test_loader.dataset)} samples\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create test dataloader: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    model = create_model_with_pretrained(config['model'], pretrained_path=args.pretrained_path, device=args.device)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Visualize samples\n",
    "logger.info(\"Starting sample visualization...\")\n",
    "try:\n",
    "    inference_fn = get_training_loop_by_model_name(\"rv_transformer_autoregressive\", model=model, save_dir=save_dir, mode=args.mode, loss_fn_name=\"mse\").forward_pass\n",
    "    gt, pred, input = get_full_image_and_prediction(\n",
    "        dataset=test_loader.dataset,\n",
    "        zfile=0,\n",
    "        inference_fn=inference_fn,\n",
    "        max_samples_per_prod=args.max_samples_per_batch,\n",
    "        return_input=True, \n",
    "        device=\"cuda\"\n",
    "    )\n",
    "    display_inference_results(\n",
    "        input_data=input,\n",
    "        gt_data=gt,\n",
    "        pred_data=pred,\n",
    "        figsize=(20, 6),\n",
    "        vminmax=(0, 1000)  # Adjust this range based on your data\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Visualization completed successfully!\")\n",
    "    logger.info(f\"Check the visualizations in: {save_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Visualization failed with error: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sar_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
