# Configuration for Spatial Vision Transformer Training

# Data directory
data_dir: "/Data/sar_focusing"

# Training parameters
# epochs: 200
# lr: 1e-4
# mode: "parallel"  # parallel, autoregressive, encoder_decoder, encoder_only

# Model configuration
model:
  name: "spatial_transformer"
  variant: "SpatialVisionTransformer"
  
  # Spatial transformer specific parameters - OPTIMIZED FOR SCALE PRESERVATION
  input_channels: 2
  output_channels: 2
  embed_dim: 256          # Increased from 128 for better scale preservation
  num_layers: 6
  num_heads: 8
  mlp_ratio: 2.0          # Reduced from 4.0 for better scale preservation
  patch_size: [100, 20]   # Optimal compression ratio 15.6:1 (vs 78.1:1)
  max_height: 5000
  max_width: 100
  dropout: 0.0
  # attention_dropout: 0.1
  pos_encoding_type: "sinusoidal"  # "sinusoidal" or "learned"
  output_mode: "complex"  # "complex", "magnitude", "real", "imag"
  
  # Removed redundant/unused parameters for cleaner config
  # num_anchors: 32       # Not used in spatial transformer
  # latent_dim: 64        # Not used in spatial transformer
  # use_rvq: False        # Not used in spatial transformer
  # rvq_codes: 2048       # Not used in spatial transformer
  # rvq_stages: 3         # Not used in spatial transformer

# Training configuration
training:
  patience: 30         # Early stopping patience
  delta: 0.00001       # Minimum improvement threshold
  weight_decay: 0.001  # L2 regularization
  epochs: 300          # Maximum epochs
  lr: 0.0001           # Learning rate
  scheduler_type: "cosine"
  loss_fn: "complex_mse"
  save_dir: "./results/spatial_transformer"
  mode: "parallel"
  warmup_epochs: 10    # Warmup epochs
  warmup_start_lr: 0.00001

# Device configuration
device: "cuda"

# Dataloader configuration
dataloader:
  data_dir: "/Data/sar_focusing"
  level_from: "rc"
  level_to: "rcmc"
  num_workers: 0
  patch_mode: "rectangular"
  patch_size: [5000, 100]
  buffer: [1000, 1000]
  stride: [5000, 100]
  max_base_sample_size: [5000, 5000]
  shuffle_files: false
  complex_valued: false  # Use real-channel representation for spatial processing
  save_samples: false
  backend: "zarr"
  verbose: false
  cache_size: 1000
  online: true
  concatenate_patches: false
  concat_axis: 0
  positional_encoding: false
  train: 
      batch_size: 5
      samples_per_prod: 50
      patch_order: "row"
      max_products: 5
      filters: {
        "years": [
          2023,
        ],
        "polarizations": [
          "vv",
        ]
      }
  validation: 
    batch_size: 5
    samples_per_prod: 50
    patch_order: "row"
    max_products: 5
    filters: {
      "years": [
        2024,
      ],
      "polarizations": [
        "vv",
      ]
    }
  test: 
    batch_size: 5
    samples_per_prod: 50
    patch_order: "row"
    max_products: 5
    filters: {
      "years": [
        2025,
      ],
      "polarizations": [
        "vv",
      ]
    }
  inference: 
    batch_size: 5
    samples_per_prod: 100
    patch_order: "row"
    max_products: 5
    filters: {
      "years": [
        2024,
      ],
      "polarizations": [
        "vv",
      ]
    }

# Logging configuration
logging:
  wandb:
    project: "sar_focusing"
    entity: null
    name: "spatial_transformer_experiment"
    tags: ["spatial", "transformer", "autoencoder", "sar"]
    notes: "Spatial Vision Transformer for SAR focusing with patch-based tokenization"
    log_freq: 10
    log_images: true
    log_model: false
  
  checkpointing:
    save_freq: 1
    save_best: true
    save_last: true
    
  visualization:
    enabled: true
    freq: 10
    save_plots: true
    plot_dir: "./results/spatial_transformer/plots"
    max_samples: 5

# Optimization settings
optimization:
  gradient_clipping: 1.0
  accumulate_grad_batches: 1
  mixed_precision: true
  compile_model: false  # Set to true for PyTorch 2.0+

# Evaluation settings  
evaluation:
  metrics: ["mse", "mae", "ssim", "psnr"]
  eval_freq: 5
  save_predictions: true
  max_eval_samples: 50