# =============================
# SARPyX Configuration File: rv_transformer_autoregressive.yaml
# =============================
#
# This YAML file configures the row-variant transformer in autoregressive mode for SAR data.
#
# Sections:
#   - model: Model architecture and hyperparameters.
#   - dataloader: Data loading options.
#   - training: Training hyperparameters and settings.
#
# model:
#   name: Model type (e.g., rv_transformer_autoregressive)
#   input_channels: Number of input channels (e.g., 2 for real/imag)
#   output_channels: Number of output channels
#   hidden_dim: Hidden dimension size
#   num_layers: Number of transformer layers
#   num_heads: Number of attention heads
#   dropout: Dropout rate
#   ... (see model docstrings for more)
#
# dataloader:
#   data_dir: Path to Zarr data directory
#   patch_size: Patch size (height, width)
#   level_from: Input SAR processing level (e.g., rcmc)
#   level_to: Target SAR processing level (e.g., az)
#   batch_size: Batch size
#   patch_mode: Patch extraction mode (rectangular, parabolic)
#   buffer: Buffer for patch extraction
#   stride: Stride for patch extraction
#   online: Use remote Hugging Face Zarr stores (true/false)
#   max_products: Max number of Zarr products
#   samples_per_prod: Number of patches per product
#   ... (see SARZarrDataset docstring for more)
#
# training:
#   save_dir: Directory to save results
#   num_epochs: Number of epochs
#   learning_rate: Learning rate
#   device: cuda or cpu
#   ... (see training script for more)

# Configuration for Real-Valued Transformer training on SAR data
# Dataset
data_dir: "/Data_large/marine/PythonProjects/SAR/sarpyx/data"

# Training parameters
epochs: 200
lr: 1e-3
# Model configuration
model:
  name: "rv_transformer"
  seq_len: 1000  # Maximum number of patches in column (1000, 1)
  input_dim: 2000   # patch size (1000, 1) * (num_channels + pos_encoding_shape)
  model_dim: 1024
  num_layers: 4
  num_heads: 4
  ff_dim: 256
  dropout: 0.1
  dim_head: 16
  mode: "autoregressive"


# Training-specific parameters
training:
  patience: 20
  delta: 0.001

# Data loader configuration
dataloader:
  data_dir: "/Data_large/marine/PythonProjects/SAR/sarpyx/data"
  level_from: "rcmc"
  level_to: "az"
  num_workers: 0
  patch_mode: "rectangular"
  patch_size: [1000, 1]
  buffer: [1000, 1000]
  stride: [1000, 1]
  max_base_sample_size: [10000, 10000]
  shuffle_files: false
  complex_valued: false
  save_samples: false
  backend: "zarr"
  verbose: false
  cache_size: 1000
  online: true
  positional_encoding: true
  concatenate_patches: true
  concat_axis: 0
  train: 
    batch_size: 16
    samples_per_prod: 100
    patch_order: "row"
    max_products: 1
    filters: {
      "years": [
        2023,
      ],
      "polarizations": [
        "vv",
      ]
    }
  validation: 
    batch_size: 16
    samples_per_prod: 1000
    patch_order: "row"
    max_products: 1
    filters: {
      "years": [
        2024,
      ],
      "polarizations": [
        "vv",
      ]
    }
  test: 
    batch_size: 16
    samples_per_prod: 5000
    patch_order: "row"
    max_products: 1
    filters: {
      "years": [
        2025,
      ],
      "polarizations": [
        "vv",
      ]
    }
  inference: 
    batch_size: 16
    samples_per_prod: 2000
    patch_order: "chunk"
    max_products: 5
    filters: {
      "years": [
        2024,
      ],
      "polarizations": [
        "vv",
      ]
    }
transforms:
  normalize: true
  complex_valued: false
  rc_min: -3000.0    
  rc_max: 3000.0     
  gt_min: -12000.0   
  gt_max: 12000.0    

# Device configurationcentral
device: "cuda"  # or "cpu"

# Output configuration
base_save_dir: "./results/rv_autoregressive"
save_results: true