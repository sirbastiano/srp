# Configuration for Mamba SSM Training

# Data directory
data_dir: "/Data/sar_focusing"

# Training parameters  
epochs: 200
batch_size: 24
lr: 5e-4
mode: "column_wise"

# Model configuration
model:
  name: "mamba_ssm"
  input_dim: 4
  state_dim: 256
  output_dim: 2
  num_layers: 8
  expansion_factor: 2
  dropout: 0.1
  use_pos_encoding: true

# Training configuration
training:
  patience: 25
  delta: 0.0001
  weight_decay: 1e-4

# Base save directory
base_save_dir: "./results/mamba_ssm_results"

# Device configuration
device: "cuda"

# Dataloader configuration
dataloader:
  level_from: "rcmc"
  level_to: "az"
  num_workers: 4
  patch_mode: "rectangular"
  patch_size: [1000, 1]  # Vertical columns
  buffer: [1000, 1000]
  stride: [500, 1]  # Overlapping columns for more data
  shuffle_files: true
  complex_valued: false
  save_samples: false
  backend: "zarr"
  verbose: true
  cache_size: 1000
  online: false
  concatenate_patches: false
  positional_encoding: true
  
  # Training split
  train:
    batch_size: 24
    samples_per_prod: 4000
    patch_order: "col"
    max_products: 5
    pattern: "*052337*.zarr"
    
  # Validation split  
  validation:
    batch_size: 24
    samples_per_prod: 1500
    patch_order: "col"
    max_products: 1
    pattern: "*048442*.zarr"
    
  # Test split
  test:
    batch_size: 12
    samples_per_prod: 800
    patch_order: "col"
    max_products: 1
    pattern: "*049667*.zarr"

# Transform configuration
transforms:
  normalize: true
  complex_valued: false
  rc_min: -3000
  rc_max: 3000
  gt_min: -12000
  gt_max: 12000
